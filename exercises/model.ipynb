{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5462db76",
   "metadata": {},
   "source": [
    "# Decision Tree Exercises\n",
    "\n",
    "Using the titanic data, in your classification-exercises repository, create a notebook, `model.ipynb` where you will do the following:\n",
    "\n",
    "1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n",
    "2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n",
    "3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n",
    "4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n",
    "5. Run through steps 2-4 using a different max_depth value.\n",
    "\n",
    "6. Which model performs better on your in-sample data?\n",
    "\n",
    "7. Which model performs best on your out-of-sample data, the validate set?\n",
    "\n",
    "8. Work through these same exercises using the Telco dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd692473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General DS Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from pydataset import data\n",
    "import env\n",
    "import math\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f1b6513",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree and Model Evaluation Imports\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "060355bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>886</td>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>Second</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>887</td>\n",
       "      <td>887</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>B</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>888</td>\n",
       "      <td>888</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>889</td>\n",
       "      <td>889</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>890</td>\n",
       "      <td>890</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "0             0             0         0       3    male  22.0      1      0   \n",
       "1             1             1         1       1  female  38.0      1      0   \n",
       "2             2             2         1       3  female  26.0      0      0   \n",
       "3             3             3         1       1  female  35.0      1      0   \n",
       "4             4             4         0       3    male  35.0      0      0   \n",
       "..          ...           ...       ...     ...     ...   ...    ...    ...   \n",
       "886         886           886         0       2    male  27.0      0      0   \n",
       "887         887           887         1       1  female  19.0      0      0   \n",
       "888         888           888         0       3  female   NaN      1      2   \n",
       "889         889           889         1       1    male  26.0      0      0   \n",
       "890         890           890         0       3    male  32.0      0      0   \n",
       "\n",
       "        fare embarked   class deck  embark_town  alone  \n",
       "0     7.2500        S   Third  NaN  Southampton      0  \n",
       "1    71.2833        C   First    C    Cherbourg      0  \n",
       "2     7.9250        S   Third  NaN  Southampton      1  \n",
       "3    53.1000        S   First    C  Southampton      0  \n",
       "4     8.0500        S   Third  NaN  Southampton      1  \n",
       "..       ...      ...     ...  ...          ...    ...  \n",
       "886  13.0000        S  Second  NaN  Southampton      1  \n",
       "887  30.0000        S   First    B  Southampton      1  \n",
       "888  23.4500        S   Third  NaN  Southampton      0  \n",
       "889  30.0000        C   First    C    Cherbourg      1  \n",
       "890   7.7500        Q   Third  NaN   Queenstown      1  \n",
       "\n",
       "[891 rows x 14 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = acquire.get_titanic_data()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95ee8f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>embarked_encode</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  passenger_id  survived  pclass     sex   age  sibsp  parch  \\\n",
       "0           0             0         0       3    male  22.0      1      0   \n",
       "1           1             1         1       1  female  38.0      1      0   \n",
       "2           2             2         1       3  female  26.0      0      0   \n",
       "3           3             3         1       1  female  35.0      1      0   \n",
       "4           4             4         0       3    male  35.0      0      0   \n",
       "\n",
       "      fare embarked  class  embark_town  alone  embarked_encode  \n",
       "0   7.2500        S  Third  Southampton      0                3  \n",
       "1  71.2833        C  First    Cherbourg      0                0  \n",
       "2   7.9250        S  Third  Southampton      1                3  \n",
       "3  53.1000        S  First  Southampton      0                3  \n",
       "4   8.0500        S  Third  Southampton      1                3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = prepare.prep_titanic_data(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "833ff198",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    549\n",
       "1    342\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "87b3342e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age = df.age.fillna(df.age.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5888fe4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   Unnamed: 0       891 non-null    int64  \n",
      " 1   passenger_id     891 non-null    int64  \n",
      " 2   survived         891 non-null    int64  \n",
      " 3   pclass           891 non-null    int64  \n",
      " 4   sex              891 non-null    object \n",
      " 5   age              891 non-null    float64\n",
      " 6   sibsp            891 non-null    int64  \n",
      " 7   parch            891 non-null    int64  \n",
      " 8   fare             891 non-null    float64\n",
      " 9   embarked         891 non-null    object \n",
      " 10  class            891 non-null    object \n",
      " 11  embark_town      891 non-null    object \n",
      " 12  alone            891 non-null    int64  \n",
      " 13  embarked_encode  891 non-null    int64  \n",
      "dtypes: float64(2), int64(8), object(4)\n",
      "memory usage: 97.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "669cef55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', 'pclass', 'embarked', 'embarked_encode', 'passenger_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a395b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>class</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>First</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>First</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>Third</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived     sex   age  sibsp  parch     fare  class  embark_town  alone\n",
       "0         0    male  22.0      1      0   7.2500  Third  Southampton      0\n",
       "1         1  female  38.0      1      0  71.2833  First    Cherbourg      0\n",
       "2         1  female  26.0      0      0   7.9250  Third  Southampton      1\n",
       "3         1  female  35.0      1      0  53.1000  First  Southampton      0\n",
       "4         0    male  35.0      0      0   8.0500  Third  Southampton      1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e648758b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived   age  sibsp  parch     fare  alone  sex_male  class_Second  \\\n",
       "0         0  22.0      1      0   7.2500      0         1             0   \n",
       "1         1  38.0      1      0  71.2833      0         0             0   \n",
       "2         1  26.0      0      0   7.9250      1         0             0   \n",
       "3         1  35.0      1      0  53.1000      0         0             0   \n",
       "4         0  35.0      0      0   8.0500      1         1             0   \n",
       "\n",
       "   class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "0            1                  0                       0   \n",
       "1            0                  0                       0   \n",
       "2            1                  0                       0   \n",
       "3            0                  0                       0   \n",
       "4            1                  0                       0   \n",
       "\n",
       "   embark_town_Southampton  \n",
       "0                        1  \n",
       "1                        0  \n",
       "2                        1  \n",
       "3                        1  \n",
       "4                        1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df,['sex', 'class', 'embark_town'], drop_first=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a112d385",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.split(df, stratify_by='survived')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8c0b1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"survived\"])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=[\"survived\"])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=[\"survived\"])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d645a436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sibsp  parch      fare  alone  sex_male  class_Second  \\\n",
       "583  36.000000      0      0   40.1250      1         1             0   \n",
       "165   9.000000      0      2   20.5250      0         1             0   \n",
       "50    7.000000      4      1   39.6875      0         1             0   \n",
       "259  50.000000      0      1   26.0000      0         0             1   \n",
       "306  29.699118      0      0  110.8833      1         0             0   \n",
       "\n",
       "     class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "583            0                  0                       0   \n",
       "165            1                  0                       0   \n",
       "50             1                  0                       0   \n",
       "259            0                  0                       0   \n",
       "306            0                  0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eb9a68fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583    0\n",
       "165    1\n",
       "50     0\n",
       "259    1\n",
       "306    1\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e9a6c",
   "metadata": {},
   "source": [
    "### 1. Baseline & Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "194c79bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# baseline prediction is equivalent to the ratio of not survived \n",
    "# in our train set over the total number of values.\n",
    "# baseline = 329/534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffb218f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['baseline'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46d59b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <th>baseline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived        age  sibsp  parch      fare  alone  sex_male  \\\n",
       "583         0  36.000000      0      0   40.1250      1         1   \n",
       "165         1   9.000000      0      2   20.5250      0         1   \n",
       "50          0   7.000000      4      1   39.6875      0         1   \n",
       "259         1  50.000000      0      1   26.0000      0         0   \n",
       "306         1  29.699118      0      0  110.8833      1         0   \n",
       "\n",
       "     class_Second  class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "583             0            0                  0                       0   \n",
       "165             0            1                  0                       0   \n",
       "50              0            1                  0                       0   \n",
       "259             1            0                  0                       0   \n",
       "306             0            0                  0                       0   \n",
       "\n",
       "     embark_town_Southampton  baseline  \n",
       "583                        0         0  \n",
       "165                        1         0  \n",
       "50                         1         0  \n",
       "259                        1         0  \n",
       "306                        0         0  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60206d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6164658634538153"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train.survived == train.baseline).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "762ac81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "baseline accuracy: 61.65%\n"
     ]
    }
   ],
   "source": [
    "# Baseline accuracy:\n",
    "\n",
    "baseline_accuracy = (train.survived == train.baseline).mean()\n",
    "\n",
    "print(f'baseline accuracy: {baseline_accuracy:.2%}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "296cc1e4",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46545b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1 = tree1.fit(X_train, y_train)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions = tree1.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "91cddf81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree1, feature_names=X_train.columns, class_names=['Died', 'survived'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a169d",
   "metadata": {},
   "source": [
    "### 3. Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4fe367e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8253012048192772"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree1.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0021309",
   "metadata": {},
   "source": [
    "The accuracy of our decision tree on our training set: 0.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e20a676",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f7af8749e20>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(tree1, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "542302e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.90      0.86       307\n",
      "           1       0.82      0.70      0.75       191\n",
      "\n",
      "    accuracy                           0.83       498\n",
      "   macro avg       0.82      0.80      0.81       498\n",
      "weighted avg       0.82      0.83      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, y_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9cb434ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree of 1 depth\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>macro avg</th>\n",
       "      <th>weighted avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.829341</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.823207</td>\n",
       "      <td>0.824636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.902280</td>\n",
       "      <td>0.701571</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.801925</td>\n",
       "      <td>0.825301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1-score</th>\n",
       "      <td>0.864275</td>\n",
       "      <td>0.754930</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.809602</td>\n",
       "      <td>0.822337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>support</th>\n",
       "      <td>307.000000</td>\n",
       "      <td>191.000000</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>498.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0           1  accuracy   macro avg  weighted avg\n",
       "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
       "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
       "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
       "support    307.000000  191.000000  0.825301  498.000000    498.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89a0579",
   "metadata": {},
   "source": [
    "## 4. Calculate Metrics\n",
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd3b6153",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f496c920",
   "metadata": {},
   "source": [
    "The label of positive and negative is arbitrary. What is sklearn considering to be the positive case here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0408be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(277, 30, 57, 134)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9618a37d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Cases: 307\n",
      "Positive Cases: 191\n",
      "0    307\n",
      "1    191\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b890c67",
   "metadata": {},
   "source": [
    "**Sklearn is calling survival (1) our positive case**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "74165d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8253012048192772 \n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.7015706806282722 \n",
      "\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.09771986970684039 \n",
      "\n",
      "True Negative Rate/Specificity/Selectivity: 0.9022801302931596 \n",
      "\n",
      "False Negative Rate/Miss Rate: 0.29842931937172773 \n",
      "\n",
      "Precision/PPV: 0.8170731707317073 \n",
      "\n",
      "F1 Score: 0.7549295774647887 \n",
      "\n",
      "Support (0): 307 \n",
      "\n",
      "Support (1): 191\n"
     ]
    }
   ],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186cb705",
   "metadata": {},
   "source": [
    "### 5. Finding Optimal max_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d40f8a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Tree with max depth of 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 10\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 11\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 12\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 13\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 14\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 15\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 16\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 17\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 18\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 19\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n",
      " Tree with max depth of 20\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.829341    0.817073  0.825301    0.823207      0.824636\n",
      "recall       0.902280    0.701571  0.825301    0.801925      0.825301\n",
      "f1-score     0.864275    0.754930  0.825301    0.809602      0.822337\n",
      "support    307.000000  191.000000  0.825301  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# making a loop to create number of decision trees each with greater depth:\n",
    "for i in range(1,21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "    \n",
    "    # Fit the model (on train only)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "    \n",
    "    #Evaluate model's performance on train first\n",
    "    y_predictions = tree1.predict(X_train)\n",
    "    \n",
    "    #Produce classification report on actual y values and each model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\" Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bbbd4",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc58de8a",
   "metadata": {},
   "source": [
    "max_depth of 15 and above generates the highest accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f22c38c",
   "metadata": {},
   "source": [
    "### 7. Validation - Which model performs best on your out-of-sample data, the validate set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bdc377ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.049675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.080415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>0.129846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.126562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>0.152667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.162050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.156758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.167492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.195567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>0.181549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>0.220283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  difference\n",
       "0           1        0.799197           0.761682    0.037515\n",
       "1           2        0.799197           0.761682    0.037515\n",
       "2           3        0.825301           0.799065    0.026236\n",
       "3           4        0.835341           0.794393    0.040949\n",
       "4           5        0.853414           0.803738    0.049675\n",
       "5           6        0.865462           0.785047    0.080415\n",
       "6           7        0.877510           0.747664    0.129846\n",
       "7           8        0.897590           0.771028    0.126562\n",
       "8           9        0.923695           0.771028    0.152667\n",
       "9          10        0.937751           0.775701    0.162050\n",
       "10         11        0.955823           0.799065    0.156758\n",
       "11         12        0.975904           0.808411    0.167492\n",
       "12         13        0.989960           0.794393    0.195567\n",
       "13         14        0.989960           0.808411    0.181549\n",
       "14         15        0.995984           0.775701    0.220283\n",
       "15         16        0.995984           0.799065    0.196919\n",
       "16         17        0.995984           0.799065    0.196919\n",
       "17         18        0.995984           0.799065    0.196919\n",
       "18         19        0.995984           0.799065    0.196919\n",
       "19         20        0.995984           0.799065    0.196919\n",
       "20         21        0.995984           0.799065    0.196919\n",
       "21         22        0.995984           0.799065    0.196919\n",
       "22         23        0.995984           0.799065    0.196919\n",
       "23         24        0.995984           0.799065    0.196919"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d23bea5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(df.max_depth, df.train_accuracy, marker = 'o')\n",
    "plt.plot(df.max_depth, df.validate_accuracy, marker = 'o')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1864ad54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>0.049675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>0.080415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   max_depth  train_accuracy  validate_accuracy  difference\n",
       "4          5        0.853414           0.803738    0.049675\n",
       "2          3        0.825301           0.799065    0.026236\n",
       "3          4        0.835341           0.794393    0.040949\n",
       "5          6        0.865462           0.785047    0.080415\n",
       "0          1        0.799197           0.761682    0.037515\n",
       "1          2        0.799197           0.761682    0.037515"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1b515",
   "metadata": {},
   "source": [
    "# Random Forest Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c86c0b",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "- After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "09cac16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "from pydataset import data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68dd1bcc",
   "metadata": {},
   "source": [
    "1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "179c9f15",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>class_Second</th>\n",
       "      <th>class_Third</th>\n",
       "      <th>embark_town_Other</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           age  sibsp  parch      fare  alone  sex_male  class_Second  \\\n",
       "583  36.000000      0      0   40.1250      1         1             0   \n",
       "165   9.000000      0      2   20.5250      0         1             0   \n",
       "50    7.000000      4      1   39.6875      0         1             0   \n",
       "259  50.000000      0      1   26.0000      0         0             1   \n",
       "306  29.699118      0      0  110.8833      1         0             0   \n",
       "\n",
       "     class_Third  embark_town_Other  embark_town_Queenstown  \\\n",
       "583            0                  0                       0   \n",
       "165            1                  0                       0   \n",
       "50             1                  0                       0   \n",
       "259            0                  0                       0   \n",
       "306            0                  0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6dc8ec08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 11), (214, 11), (179, 11))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_validate.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95ffe6e3",
   "metadata": {},
   "source": [
    "##### EXPLORATION NOTE: Previous exploration indicates that age, sex, fare, class, alone status and embark_town all are valid features to include in our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8208a26b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    307\n",
       "1    191\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9abc8d62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(max_depth=10, min_samples_leaf=1, \n",
    "                            random_state=123)\n",
    "rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c12baa6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=10, random_state=123)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "248c4c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.12370197e-01 5.47282154e-02 3.47804130e-02 2.53696522e-01\n",
      " 2.09353487e-02 2.95016512e-01 1.79287464e-02 6.97923944e-02\n",
      " 2.86967830e-04 1.40123282e-02 2.64523549e-02]\n"
     ]
    }
   ],
   "source": [
    "# Feature importance\n",
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5a9f3f0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rf.predict(X_train)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ef2b0db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.75929355, 0.24070645],\n",
       "       [0.2463612 , 0.7536388 ],\n",
       "       [0.9507381 , 0.0492619 ],\n",
       "       [0.0208    , 0.9792    ],\n",
       "       [0.01241379, 0.98758621],\n",
       "       [0.82142262, 0.17857738],\n",
       "       [0.87863043, 0.12136957],\n",
       "       [0.95576234, 0.04423766],\n",
       "       [0.97530773, 0.02469227],\n",
       "       [1.        , 0.        ],\n",
       "       [0.77567576, 0.22432424],\n",
       "       [0.90112367, 0.09887633],\n",
       "       [0.0333    , 0.9667    ],\n",
       "       [0.67370867, 0.32629133],\n",
       "       [0.85342756, 0.14657244],\n",
       "       [0.59754483, 0.40245517],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.0333908 , 0.9666092 ],\n",
       "       [0.63117782, 0.36882218],\n",
       "       [0.80304203, 0.19695797],\n",
       "       [0.24282401, 0.75717599],\n",
       "       [0.96827401, 0.03172599],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.02654423, 0.97345577],\n",
       "       [0.59022058, 0.40977942],\n",
       "       [0.9776132 , 0.0223868 ],\n",
       "       [0.04333333, 0.95666667],\n",
       "       [0.75052189, 0.24947811],\n",
       "       [0.83122834, 0.16877166],\n",
       "       [0.93779347, 0.06220653],\n",
       "       [0.96913464, 0.03086536],\n",
       "       [0.96954859, 0.03045141],\n",
       "       [0.9711132 , 0.0288868 ],\n",
       "       [0.11946374, 0.88053626],\n",
       "       [0.01923116, 0.98076884],\n",
       "       [0.41549228, 0.58450772],\n",
       "       [0.85410865, 0.14589135],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.95494297, 0.04505703],\n",
       "       [0.06083333, 0.93916667],\n",
       "       [0.92902142, 0.07097858],\n",
       "       [0.98120626, 0.01879374],\n",
       "       [0.79681951, 0.20318049],\n",
       "       [0.07854167, 0.92145833],\n",
       "       [0.57494242, 0.42505758],\n",
       "       [0.96909226, 0.03090774],\n",
       "       [0.97530773, 0.02469227],\n",
       "       [0.96394671, 0.03605329],\n",
       "       [0.04160362, 0.95839638],\n",
       "       [0.87256645, 0.12743355],\n",
       "       [0.92417808, 0.07582192],\n",
       "       [0.95332972, 0.04667028],\n",
       "       [0.03411765, 0.96588235],\n",
       "       [0.03127743, 0.96872257],\n",
       "       [0.79277529, 0.20722471],\n",
       "       [0.14243813, 0.85756187],\n",
       "       [0.96913464, 0.03086536],\n",
       "       [0.01738267, 0.98261733],\n",
       "       [0.35159524, 0.64840476],\n",
       "       [0.94905432, 0.05094568],\n",
       "       [0.882     , 0.118     ],\n",
       "       [0.97696079, 0.02303921],\n",
       "       [0.94830382, 0.05169618],\n",
       "       [0.8225405 , 0.1774595 ],\n",
       "       [0.88730515, 0.11269485],\n",
       "       [0.97530773, 0.02469227],\n",
       "       [0.44223757, 0.55776243],\n",
       "       [0.91687948, 0.08312052],\n",
       "       [0.37388889, 0.62611111],\n",
       "       [0.0195037 , 0.9804963 ],\n",
       "       [0.91666667, 0.08333333],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.03321601, 0.96678399],\n",
       "       [0.28484342, 0.71515658],\n",
       "       [0.97530773, 0.02469227],\n",
       "       [0.88775797, 0.11224203],\n",
       "       [0.9809689 , 0.0190311 ],\n",
       "       [0.94485868, 0.05514132],\n",
       "       [0.9787487 , 0.0212513 ],\n",
       "       [0.3572381 , 0.6427619 ],\n",
       "       [0.8823001 , 0.1176999 ],\n",
       "       [0.01241379, 0.98758621],\n",
       "       [0.95088478, 0.04911522],\n",
       "       [0.91555155, 0.08444845],\n",
       "       [0.88582266, 0.11417734],\n",
       "       [0.91491039, 0.08508961],\n",
       "       [0.        , 1.        ],\n",
       "       [0.17125663, 0.82874337],\n",
       "       [0.10833333, 0.89166667],\n",
       "       [0.94485868, 0.05514132],\n",
       "       [0.92767909, 0.07232091],\n",
       "       [0.97530773, 0.02469227],\n",
       "       [0.21947552, 0.78052448],\n",
       "       [0.02241379, 0.97758621],\n",
       "       [0.71977641, 0.28022359],\n",
       "       [0.97133928, 0.02866072],\n",
       "       [0.        , 1.        ],\n",
       "       [0.83172807, 0.16827193],\n",
       "       [0.85504015, 0.14495985],\n",
       "       [0.04643813, 0.95356187],\n",
       "       [0.95498932, 0.04501068],\n",
       "       [0.84036782, 0.15963218],\n",
       "       [0.0525    , 0.9475    ],\n",
       "       [0.94734594, 0.05265406],\n",
       "       [0.64413043, 0.35586957],\n",
       "       [0.00340909, 0.99659091],\n",
       "       [0.80196377, 0.19803623],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.97133928, 0.02866072],\n",
       "       [0.98229688, 0.01770312],\n",
       "       [0.19195517, 0.80804483],\n",
       "       [0.24617631, 0.75382369],\n",
       "       [0.94089394, 0.05910606],\n",
       "       [0.96239027, 0.03760973],\n",
       "       [0.69156494, 0.30843506],\n",
       "       [0.03163333, 0.96836667],\n",
       "       [0.985     , 0.015     ],\n",
       "       [0.96825395, 0.03174605],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.83251349, 0.16748651],\n",
       "       [0.99199882, 0.00800118],\n",
       "       [0.79529859, 0.20470141],\n",
       "       [0.81673303, 0.18326697],\n",
       "       [0.0995    , 0.9005    ],\n",
       "       [0.09020833, 0.90979167],\n",
       "       [0.01333333, 0.98666667],\n",
       "       [0.75175326, 0.24824674],\n",
       "       [0.45163699, 0.54836301],\n",
       "       [0.86361111, 0.13638889],\n",
       "       [0.0333908 , 0.9666092 ],\n",
       "       [0.92970727, 0.07029273],\n",
       "       [0.98923077, 0.01076923],\n",
       "       [0.06913333, 0.93086667],\n",
       "       [0.92013344, 0.07986656],\n",
       "       [0.96617592, 0.03382408],\n",
       "       [0.95942737, 0.04057263],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.84800817, 0.15199183],\n",
       "       [0.7737612 , 0.2262388 ],\n",
       "       [0.02583333, 0.97416667],\n",
       "       [0.92475193, 0.07524807],\n",
       "       [0.72129837, 0.27870163],\n",
       "       [0.98407313, 0.01592687],\n",
       "       [0.122     , 0.878     ],\n",
       "       [0.26478912, 0.73521088],\n",
       "       [0.        , 1.        ],\n",
       "       [0.05117037, 0.94882963],\n",
       "       [0.08846154, 0.91153846],\n",
       "       [0.07643813, 0.92356187],\n",
       "       [0.97696079, 0.02303921],\n",
       "       [0.0133    , 0.9867    ],\n",
       "       [0.20052189, 0.79947811],\n",
       "       [0.96233583, 0.03766417],\n",
       "       [0.67937436, 0.32062564],\n",
       "       [0.14726154, 0.85273846],\n",
       "       [0.96617486, 0.03382514],\n",
       "       [0.96168671, 0.03831329],\n",
       "       [0.18529004, 0.81470996],\n",
       "       [0.86534685, 0.13465315],\n",
       "       [0.89469908, 0.10530092],\n",
       "       [0.02256449, 0.97743551],\n",
       "       [0.89817702, 0.10182298],\n",
       "       [0.16399807, 0.83600193],\n",
       "       [0.94791254, 0.05208746],\n",
       "       [0.96144826, 0.03855174],\n",
       "       [0.8897381 , 0.1102619 ],\n",
       "       [0.96825395, 0.03174605],\n",
       "       [0.91409917, 0.08590083],\n",
       "       [0.93448969, 0.06551031],\n",
       "       [0.95219772, 0.04780228],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.18529004, 0.81470996],\n",
       "       [0.90772101, 0.09227899],\n",
       "       [0.79164079, 0.20835921],\n",
       "       [0.95080854, 0.04919146],\n",
       "       [0.10013037, 0.89986963],\n",
       "       [0.91074566, 0.08925434],\n",
       "       [0.97840965, 0.02159035],\n",
       "       [0.42536682, 0.57463318],\n",
       "       [0.96140598, 0.03859402],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.96647978, 0.03352022],\n",
       "       [0.01230769, 0.98769231],\n",
       "       [0.98229688, 0.01770312],\n",
       "       [0.05043696, 0.94956304],\n",
       "       [0.97051619, 0.02948381],\n",
       "       [0.02333333, 0.97666667],\n",
       "       [0.78784615, 0.21215385],\n",
       "       [0.43838019, 0.56161981],\n",
       "       [0.93422602, 0.06577398],\n",
       "       [0.04411765, 0.95588235],\n",
       "       [0.93459263, 0.06540737],\n",
       "       [0.94533449, 0.05466551],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.26738403, 0.73261597],\n",
       "       [0.9225    , 0.0775    ],\n",
       "       [0.43583981, 0.56416019],\n",
       "       [0.91570133, 0.08429867],\n",
       "       [0.92122848, 0.07877152],\n",
       "       [0.985     , 0.015     ],\n",
       "       [0.04      , 0.96      ],\n",
       "       [0.06      , 0.94      ],\n",
       "       [0.92238231, 0.07761769],\n",
       "       [0.94859524, 0.05140476],\n",
       "       [0.95117464, 0.04882536],\n",
       "       [0.87833333, 0.12166667],\n",
       "       [0.95225193, 0.04774807],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.16854167, 0.83145833],\n",
       "       [0.66357662, 0.33642338],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.83959124, 0.16040876],\n",
       "       [0.33444719, 0.66555281],\n",
       "       [0.02241379, 0.97758621],\n",
       "       [0.18798692, 0.81201308],\n",
       "       [0.9787487 , 0.0212513 ],\n",
       "       [0.99216404, 0.00783596],\n",
       "       [0.031875  , 0.968125  ],\n",
       "       [0.96700084, 0.03299916],\n",
       "       [0.82546866, 0.17453134],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.91257692, 0.08742308],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.99317529, 0.00682471],\n",
       "       [0.92767909, 0.07232091],\n",
       "       [0.75253329, 0.24746671],\n",
       "       [0.56981116, 0.43018884],\n",
       "       [0.96180459, 0.03819541],\n",
       "       [0.19509643, 0.80490357],\n",
       "       [0.84426858, 0.15573142],\n",
       "       [0.90500603, 0.09499397],\n",
       "       [0.98229688, 0.01770312],\n",
       "       [0.92834099, 0.07165901],\n",
       "       [0.92122848, 0.07877152],\n",
       "       [0.025     , 0.975     ],\n",
       "       [0.24330426, 0.75669574],\n",
       "       [0.94830382, 0.05169618],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.97923077, 0.02076923],\n",
       "       [0.93459263, 0.06540737],\n",
       "       [0.85411914, 0.14588086],\n",
       "       [0.07705   , 0.92295   ],\n",
       "       [0.53591976, 0.46408024],\n",
       "       [0.03348485, 0.96651515],\n",
       "       [0.99324485, 0.00675515],\n",
       "       [0.01846154, 0.98153846],\n",
       "       [0.94070379, 0.05929621],\n",
       "       [0.73570043, 0.26429957],\n",
       "       [0.02083333, 0.97916667],\n",
       "       [0.87310779, 0.12689221],\n",
       "       [0.83301439, 0.16698561],\n",
       "       [0.97297978, 0.02702022],\n",
       "       [0.21186477, 0.78813523],\n",
       "       [0.96104233, 0.03895767],\n",
       "       [0.25238858, 0.74761142],\n",
       "       [0.60129556, 0.39870444],\n",
       "       [0.01413043, 0.98586957],\n",
       "       [0.        , 1.        ],\n",
       "       [0.2521963 , 0.7478037 ],\n",
       "       [0.72508704, 0.27491296],\n",
       "       [0.93439603, 0.06560397],\n",
       "       [0.04160362, 0.95839638],\n",
       "       [0.07846154, 0.92153846],\n",
       "       [0.93448969, 0.06551031],\n",
       "       [0.94963697, 0.05036303],\n",
       "       [0.83804762, 0.16195238],\n",
       "       [0.35172454, 0.64827546],\n",
       "       [0.97133928, 0.02866072],\n",
       "       [0.80173993, 0.19826007],\n",
       "       [0.9263612 , 0.0736388 ],\n",
       "       [0.7695583 , 0.2304417 ],\n",
       "       [0.96175271, 0.03824729],\n",
       "       [0.01846154, 0.98153846],\n",
       "       [1.        , 0.        ],\n",
       "       [0.92174298, 0.07825702],\n",
       "       [0.96617592, 0.03382408],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.95254448, 0.04745552],\n",
       "       [0.95254448, 0.04745552],\n",
       "       [0.01241379, 0.98758621],\n",
       "       [0.67313609, 0.32686391],\n",
       "       [0.04160362, 0.95839638],\n",
       "       [0.91571383, 0.08428617],\n",
       "       [0.87692464, 0.12307536],\n",
       "       [0.04705   , 0.95295   ],\n",
       "       [0.44708084, 0.55291916],\n",
       "       [0.93      , 0.07      ],\n",
       "       [0.88887485, 0.11112515],\n",
       "       [0.94310164, 0.05689836],\n",
       "       [0.95306809, 0.04693191],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.96175271, 0.03824729],\n",
       "       [0.81782854, 0.18217146],\n",
       "       [0.44401002, 0.55598998],\n",
       "       [0.81821955, 0.18178045],\n",
       "       [0.96115546, 0.03884454],\n",
       "       [0.95857143, 0.04142857],\n",
       "       [0.91368469, 0.08631531],\n",
       "       [0.64810333, 0.35189667],\n",
       "       [0.92902142, 0.07097858],\n",
       "       [0.96391254, 0.03608746],\n",
       "       [0.04160362, 0.95839638],\n",
       "       [0.97297978, 0.02702022],\n",
       "       [0.84399132, 0.15600868],\n",
       "       [0.02411765, 0.97588235],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.89374608, 0.10625392],\n",
       "       [0.83758771, 0.16241229],\n",
       "       [0.95260722, 0.04739278],\n",
       "       [0.953     , 0.047     ],\n",
       "       [0.99638626, 0.00361374],\n",
       "       [0.07043696, 0.92956304],\n",
       "       [0.92673077, 0.07326923],\n",
       "       [0.88522807, 0.11477193],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.03074808, 0.96925192],\n",
       "       [0.43941855, 0.56058145],\n",
       "       [0.9808073 , 0.0191927 ],\n",
       "       [0.94061905, 0.05938095],\n",
       "       [0.8790299 , 0.1209701 ],\n",
       "       [0.05173293, 0.94826707],\n",
       "       [0.72543894, 0.27456106],\n",
       "       [0.8649086 , 0.1350914 ],\n",
       "       [0.25478044, 0.74521956],\n",
       "       [0.39040891, 0.60959109],\n",
       "       [0.53851439, 0.46148561],\n",
       "       [0.25360876, 0.74639124],\n",
       "       [0.01367037, 0.98632963],\n",
       "       [0.94372252, 0.05627748],\n",
       "       [0.0525    , 0.9475    ],\n",
       "       [0.04160362, 0.95839638],\n",
       "       [0.21296486, 0.78703514],\n",
       "       [0.25200065, 0.74799935],\n",
       "       [0.0333908 , 0.9666092 ],\n",
       "       [0.88123077, 0.11876923],\n",
       "       [0.24081553, 0.75918447],\n",
       "       [0.96332972, 0.03667028],\n",
       "       [0.4394567 , 0.5605433 ],\n",
       "       [0.89687284, 0.10312716],\n",
       "       [0.14093889, 0.85906111],\n",
       "       [0.25280276, 0.74719724],\n",
       "       [0.290733  , 0.709267  ],\n",
       "       [0.90946247, 0.09053753],\n",
       "       [0.2787496 , 0.7212504 ],\n",
       "       [0.87692464, 0.12307536],\n",
       "       [0.68611296, 0.31388704],\n",
       "       [0.78713043, 0.21286957],\n",
       "       [0.90112367, 0.09887633],\n",
       "       [0.00654423, 0.99345577],\n",
       "       [0.86278999, 0.13721001],\n",
       "       [0.45209837, 0.54790163],\n",
       "       [0.14513043, 0.85486957],\n",
       "       [0.0275    , 0.9725    ],\n",
       "       [0.00241379, 0.99758621],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.9305    , 0.0695    ],\n",
       "       [0.88522807, 0.11477193],\n",
       "       [0.104     , 0.896     ],\n",
       "       [0.79641351, 0.20358649],\n",
       "       [0.33775524, 0.66224476],\n",
       "       [0.0235037 , 0.9764963 ],\n",
       "       [0.8       , 0.2       ],\n",
       "       [0.98452406, 0.01547594],\n",
       "       [0.6872971 , 0.3127029 ],\n",
       "       [0.63117782, 0.36882218],\n",
       "       [0.88309041, 0.11690959],\n",
       "       [0.9482381 , 0.0517619 ],\n",
       "       [0.73786923, 0.26213077],\n",
       "       [0.94533449, 0.05466551],\n",
       "       [0.87664898, 0.12335102],\n",
       "       [0.15086378, 0.84913622],\n",
       "       [0.85687894, 0.14312106],\n",
       "       [0.24085512, 0.75914488],\n",
       "       [0.66829957, 0.33170043],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.62020833, 0.37979167],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.3201746 , 0.6798254 ],\n",
       "       [0.02      , 0.98      ],\n",
       "       [0.0408    , 0.9592    ],\n",
       "       [0.0195037 , 0.9804963 ],\n",
       "       [0.87424732, 0.12575268],\n",
       "       [0.78438501, 0.21561499],\n",
       "       [0.04692505, 0.95307495],\n",
       "       [0.83959124, 0.16040876],\n",
       "       [0.20039408, 0.79960592],\n",
       "       [0.73666667, 0.26333333],\n",
       "       [0.96808118, 0.03191882],\n",
       "       [0.88764496, 0.11235504],\n",
       "       [0.66244308, 0.33755692],\n",
       "       [0.8276353 , 0.1723647 ],\n",
       "       [0.52155   , 0.47845   ],\n",
       "       [0.24308791, 0.75691209],\n",
       "       [0.75613019, 0.24386981],\n",
       "       [0.045     , 0.955     ],\n",
       "       [0.97300084, 0.02699916],\n",
       "       [0.8649086 , 0.1350914 ],\n",
       "       [0.68507488, 0.31492512],\n",
       "       [0.95866733, 0.04133267],\n",
       "       [0.09205   , 0.90795   ],\n",
       "       [0.95609064, 0.04390936],\n",
       "       [0.8358612 , 0.1641388 ],\n",
       "       [0.91077618, 0.08922382],\n",
       "       [0.67935933, 0.32064067],\n",
       "       [0.95747822, 0.04252178],\n",
       "       [0.80784078, 0.19215922],\n",
       "       [0.98913043, 0.01086957],\n",
       "       [0.59894719, 0.40105281],\n",
       "       [0.90112367, 0.09887633],\n",
       "       [0.98638687, 0.01361313],\n",
       "       [0.94595268, 0.05404732],\n",
       "       [0.94838612, 0.05161388],\n",
       "       [0.01654423, 0.98345577],\n",
       "       [0.03256449, 0.96743551],\n",
       "       [0.00340909, 0.99659091],\n",
       "       [0.77986757, 0.22013243],\n",
       "       [0.03663043, 0.96336957],\n",
       "       [0.68597299, 0.31402701],\n",
       "       [0.36938216, 0.63061784],\n",
       "       [0.95879369, 0.04120631],\n",
       "       [0.97696079, 0.02303921],\n",
       "       [0.02413333, 0.97586667],\n",
       "       [0.92886842, 0.07113158],\n",
       "       [0.0135037 , 0.9864963 ],\n",
       "       [0.79713997, 0.20286003],\n",
       "       [0.03333333, 0.96666667],\n",
       "       [0.96439784, 0.03560216],\n",
       "       [0.7531108 , 0.2468892 ],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.86159075, 0.13840925],\n",
       "       [0.94239027, 0.05760973],\n",
       "       [0.96954859, 0.03045141],\n",
       "       [0.20733333, 0.79266667],\n",
       "       [0.60176194, 0.39823806],\n",
       "       [0.63887798, 0.36112202],\n",
       "       [0.94734594, 0.05265406],\n",
       "       [0.05643813, 0.94356187],\n",
       "       [0.98225852, 0.01774148],\n",
       "       [0.97334857, 0.02665143],\n",
       "       [0.8627638 , 0.1372362 ],\n",
       "       [0.9364619 , 0.0635381 ],\n",
       "       [0.72683704, 0.27316296],\n",
       "       [0.97133928, 0.02866072],\n",
       "       [0.24439553, 0.75560447],\n",
       "       [0.92123077, 0.07876923],\n",
       "       [0.985     , 0.015     ],\n",
       "       [0.40694212, 0.59305788],\n",
       "       [0.96919128, 0.03080872],\n",
       "       [0.18624469, 0.81375531],\n",
       "       [0.01      , 0.99      ],\n",
       "       [0.94070379, 0.05929621],\n",
       "       [0.91311642, 0.08688358],\n",
       "       [0.11903378, 0.88096622],\n",
       "       [0.33055725, 0.66944275],\n",
       "       [0.94666667, 0.05333333],\n",
       "       [0.80838897, 0.19161103],\n",
       "       [0.95887749, 0.04112251],\n",
       "       [0.94533449, 0.05466551],\n",
       "       [0.87608791, 0.12391209],\n",
       "       [0.95705586, 0.04294414],\n",
       "       [0.02256449, 0.97743551],\n",
       "       [0.89730882, 0.10269118],\n",
       "       [0.8709884 , 0.1290116 ],\n",
       "       [0.00654423, 0.99345577],\n",
       "       [0.27186477, 0.72813523],\n",
       "       [0.94893136, 0.05106864],\n",
       "       [0.27      , 0.73      ],\n",
       "       [0.94077755, 0.05922245],\n",
       "       [0.01556449, 0.98443551],\n",
       "       [0.73834953, 0.26165047],\n",
       "       [0.91368469, 0.08631531],\n",
       "       [0.92834052, 0.07165948],\n",
       "       [0.98155754, 0.01844246],\n",
       "       [0.83959124, 0.16040876],\n",
       "       [0.0245037 , 0.9754963 ],\n",
       "       [0.875     , 0.125     ],\n",
       "       [0.82053589, 0.17946411],\n",
       "       [0.96825395, 0.03174605],\n",
       "       [0.27933302, 0.72066698],\n",
       "       [0.01833333, 0.98166667],\n",
       "       [0.1315601 , 0.8684399 ],\n",
       "       [0.041     , 0.959     ],\n",
       "       [0.95088478, 0.04911522],\n",
       "       [0.34623739, 0.65376261],\n",
       "       [0.69665634, 0.30334366],\n",
       "       [0.10886378, 0.89113622],\n",
       "       [0.96283399, 0.03716601],\n",
       "       [0.35780866, 0.64219134],\n",
       "       [0.02163333, 0.97836667],\n",
       "       [0.92573621, 0.07426379],\n",
       "       [0.041     , 0.959     ],\n",
       "       [0.9750197 , 0.0249803 ],\n",
       "       [0.87856388, 0.12143612],\n",
       "       [0.78754483, 0.21245517],\n",
       "       [0.94061905, 0.05938095],\n",
       "       [0.77427525, 0.22572475]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Estimate probability\n",
    "y_pred_proba = rf.predict_proba(X_train)\n",
    "y_pred_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23b234a",
   "metadata": {},
   "source": [
    "2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41a21167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of random forest classifier on training set: 0.97\n"
     ]
    }
   ],
   "source": [
    "# computing accuracy (model score)\n",
    "rf.score(X_train, y_train)\n",
    "\n",
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "    .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7b1ff39c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>survived</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>177</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0       0    1\n",
       "survived          \n",
       "0         307    0\n",
       "1          14  177"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confusion matrix\n",
    "pd.crosstab(y_train, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "aace0d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98       307\n",
      "           1       1.00      0.93      0.96       191\n",
      "\n",
      "    accuracy                           0.97       498\n",
      "   macro avg       0.98      0.96      0.97       498\n",
      "weighted avg       0.97      0.97      0.97       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1169644",
   "metadata": {},
   "source": [
    "3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8e9fb824",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4eefc21f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307, 0, 14, 177)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TN, FP, FN, TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8fae3639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Cases: 307\n",
      "Positive Cases: 191\n",
      "0    307\n",
      "1    191\n",
      "Name: survived, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d9e23528",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9718875502008032 \n",
      "\n",
      "True Positive Rate/Sensitivity/Recall/Power: 0.9267015706806283 \n",
      "\n",
      "False Positive Rate/False Alarm Ratio/Fall-out: 0.0 \n",
      "\n",
      "True Negative Rate/Specificity/Selectivity: 1.0 \n",
      "\n",
      "False Negative Rate/Miss Rate: 0.07329842931937172 \n",
      "\n",
      "Precision/PPV: 1.0 \n",
      "\n",
      "F1 Score: 0.9619565217391305 \n",
      "\n",
      "Support (0): 307 \n",
      "\n",
      "Support (1): 191\n"
     ]
    }
   ],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e70f844",
   "metadata": {},
   "source": [
    "4. Run through steps increasing your min_samples_leaf and decreasing your max_depth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "377f2e92",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree with max depth of 10, min_samples_leaf of 1\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.920732    0.970588  0.937751    0.945660      0.939853\n",
      "recall       0.983713    0.863874  0.937751    0.923794      0.937751\n",
      "f1-score     0.951181    0.914127  0.937751    0.932654      0.936970\n",
      "support    307.000000  191.000000  0.937751  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 9, min_samples_leaf of 2\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.889231    0.895954  0.891566    0.892592      0.891809\n",
      "recall       0.941368    0.811518  0.891566    0.876443      0.891566\n",
      "f1-score     0.914557    0.851648  0.891566    0.883103      0.890429\n",
      "support    307.000000  191.000000  0.891566  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 8, min_samples_leaf of 3\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.854227    0.909677  0.871486    0.881952      0.875494\n",
      "recall       0.954397    0.738220  0.871486    0.846309      0.871486\n",
      "f1-score     0.901538    0.815029  0.871486    0.858284      0.868359\n",
      "support    307.000000  191.000000  0.871486  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 7, min_samples_leaf of 4\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.884868    0.804124  0.853414    0.844496      0.853900\n",
      "recall       0.876221    0.816754  0.853414    0.846488      0.853414\n",
      "f1-score     0.880524    0.810390  0.853414    0.845457      0.853625\n",
      "support    307.000000  191.000000  0.853414  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 6, min_samples_leaf of 5\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.823034    0.901408  0.845382    0.862221      0.853093\n",
      "recall       0.954397    0.670157  0.845382    0.812277      0.845382\n",
      "f1-score     0.883861    0.768769  0.845382    0.826315      0.839719\n",
      "support    307.000000  191.000000  0.845382  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 5, min_samples_leaf of 6\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.838806    0.840491  0.839357    0.839648      0.839452\n",
      "recall       0.915309    0.717277  0.839357    0.816293      0.839357\n",
      "f1-score     0.875389    0.774011  0.839357    0.824700      0.836507\n",
      "support    307.000000  191.000000  0.839357  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 4, min_samples_leaf of 7\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.823881    0.809816  0.819277    0.816848      0.818486\n",
      "recall       0.899023    0.691099  0.819277    0.795061      0.819277\n",
      "f1-score     0.859813    0.745763  0.819277    0.802788      0.816071\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 3, min_samples_leaf of 8\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.823881    0.809816  0.819277    0.816848      0.818486\n",
      "recall       0.899023    0.691099  0.819277    0.795061      0.819277\n",
      "f1-score     0.859813    0.745763  0.819277    0.802788      0.816071\n",
      "support    307.000000  191.000000  0.819277  498.000000    498.000000\n",
      "\n",
      "Tree with max depth of 2, min_samples_leaf of 9\n",
      "                    0           1  accuracy   macro avg  weighted avg\n",
      "precision    0.820433    0.760000  0.799197    0.790217      0.797255\n",
      "recall       0.863192    0.696335  0.799197    0.779764      0.799197\n",
      "f1-score     0.841270    0.726776  0.799197    0.784023      0.797358\n",
      "support    307.000000  191.000000  0.799197  498.000000    498.000000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Creating loop, increasing min_samples_leaf while simultaneously decreasing max_depth\n",
    "for i in range(1, 10):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=(11-i), min_samples_leaf=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {11-i}, min_samples_leaf of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a627e4",
   "metadata": {},
   "source": [
    "5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n",
    "- After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44373d05",
   "metadata": {},
   "source": [
    "Looking at our random forest iterations, we observe that as max_depth decreases nad min_samples_leaf increases, accuracy diminishes. \n",
    "Our tree with max depth of 10 and min_samples_leaf of 1 shows greatest performance with accuracy of 93.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5344e8c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.877510</td>\n",
       "      <td>0.747664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.129846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.897590</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.923695</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.152667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.162050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.955823</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.156758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.975904</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.167492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.195567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.989960</td>\n",
       "      <td>0.808411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.181549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.220283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.995984</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>10</td>\n",
       "      <td>0.937751</td>\n",
       "      <td>0.775701</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>9</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.757009</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.134557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>8</td>\n",
       "      <td>0.871486</td>\n",
       "      <td>0.771028</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.100458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.742991</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.110423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.060335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.044965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  min_samples_leaf  difference\n",
       "0           1        0.799197           0.761682               NaN    0.037515\n",
       "1           2        0.799197           0.761682               NaN    0.037515\n",
       "2           3        0.825301           0.799065               NaN    0.026236\n",
       "3           4        0.835341           0.794393               NaN    0.040949\n",
       "4           5        0.853414           0.803738               NaN    0.049675\n",
       "5           6        0.865462           0.785047               NaN    0.080415\n",
       "6           7        0.877510           0.747664               NaN    0.129846\n",
       "7           8        0.897590           0.771028               NaN    0.126562\n",
       "8           9        0.923695           0.771028               NaN    0.152667\n",
       "9          10        0.937751           0.775701               NaN    0.162050\n",
       "10         11        0.955823           0.799065               NaN    0.156758\n",
       "11         12        0.975904           0.808411               NaN    0.167492\n",
       "12         13        0.989960           0.794393               NaN    0.195567\n",
       "13         14        0.989960           0.808411               NaN    0.181549\n",
       "14         15        0.995984           0.775701               NaN    0.220283\n",
       "15         16        0.995984           0.799065               NaN    0.196919\n",
       "16         17        0.995984           0.799065               NaN    0.196919\n",
       "17         18        0.995984           0.799065               NaN    0.196919\n",
       "18         19        0.995984           0.799065               NaN    0.196919\n",
       "19         20        0.995984           0.799065               NaN    0.196919\n",
       "20         21        0.995984           0.799065               NaN    0.196919\n",
       "21         22        0.995984           0.799065               NaN    0.196919\n",
       "22         23        0.995984           0.799065               NaN    0.196919\n",
       "23         24        0.995984           0.799065               NaN    0.196919\n",
       "24         10        0.937751           0.775701               1.0    0.162050\n",
       "25          9        0.891566           0.757009               2.0    0.134557\n",
       "26          8        0.871486           0.771028               3.0    0.100458\n",
       "27          7        0.853414           0.742991               4.0    0.110423\n",
       "28          6        0.845382           0.785047               5.0    0.060335\n",
       "29          5        0.839357           0.794393               6.0    0.044965\n",
       "30          4        0.819277           0.785047               7.0    0.034230\n",
       "31          3        0.819277           0.785047               8.0    0.034230\n",
       "32          2        0.799197           0.761682               9.0    0.037515"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# same loop, now comparing in-sample to out-of-sample (validate set)\n",
    "for i in range(1, 10):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=(11-i), min_samples_leaf=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train, y_train)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate, y_validate)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": (11-i),\n",
    "        \"min_samples_leaf\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "df = pd.DataFrame(metrics)\n",
    "df[\"difference\"] = df.train_accuracy - df.validate_accuracy\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "17ce144b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>max_depth</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>validate_accuracy</th>\n",
       "      <th>min_samples_leaf</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.853414</td>\n",
       "      <td>0.803738</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.049675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.825301</td>\n",
       "      <td>0.799065</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>5</td>\n",
       "      <td>0.839357</td>\n",
       "      <td>0.794393</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.044965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>4</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>3</td>\n",
       "      <td>0.819277</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.034230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>0.845382</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.060335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.865462</td>\n",
       "      <td>0.785047</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.080415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>0.799197</td>\n",
       "      <td>0.761682</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.037515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    max_depth  train_accuracy  validate_accuracy  min_samples_leaf  difference\n",
       "4           5        0.853414           0.803738               NaN    0.049675\n",
       "2           3        0.825301           0.799065               NaN    0.026236\n",
       "3           4        0.835341           0.794393               NaN    0.040949\n",
       "29          5        0.839357           0.794393               6.0    0.044965\n",
       "30          4        0.819277           0.785047               7.0    0.034230\n",
       "31          3        0.819277           0.785047               8.0    0.034230\n",
       "28          6        0.845382           0.785047               5.0    0.060335\n",
       "5           6        0.865462           0.785047               NaN    0.080415\n",
       "0           1        0.799197           0.761682               NaN    0.037515\n",
       "1           2        0.799197           0.761682               NaN    0.037515\n",
       "32          2        0.799197           0.761682               9.0    0.037515"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a349ff8b",
   "metadata": {},
   "source": [
    "#### It seems the model with max_depth=5 (while min_samples_leaf = 6) has best performance on both train and validate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
